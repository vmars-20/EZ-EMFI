# Neural Network - Instrument API Reference

## Purpose
Deploy **trained neural networks to FPGA** for real-time inference on analog signals. Enables machine learning applications on Moku hardware with low-latency signal processing.

## Key Python API Methods

### Initialization
```python
from moku.instruments import NeuralNetwork
# Note: Requires Multi-Instrument Mode (MiM) on platforms with 3+ slots
from moku.instruments import MultiInstrument

m = MultiInstrument('192.168.1.100', platform_id=4, force_connect=True)
nn = m.set_instrument(slot=2, instrument=NeuralNetwork)
```

### Input Configuration
```python
# Configure input channel mapping and scaling
nn.set_input(
    strict=False,              # Allow flexibility in input configuration
    channel=1,                 # Input channel (1-4)
    low_level=-1,              # Minimum input value (maps to network input range)
    high_level=1               # Maximum input value
)

# Set input sample rate
nn.set_input_sample_rate(sample_rate=305000)  # Hz (platform-dependent)
```

### Network Upload
```python
# Upload pre-trained neural network model (.linn format)
nn.upload_network("/path/to/trained_model.linn")
# .linn = Liquid Instruments Neural Network format (generated by training tools)
```

### Output Configuration
```python
# Configure output channel mapping and scaling
nn.set_output(
    strict=False,
    channel=1,                 # Output channel (1-4)
    enabled=True,              # Enable this output
    low_level=-1,              # Network output range minimum
    high_level=1               # Network output range maximum
)
```

### Status Check
```python
# Get instrument configuration summary
summary = nn.summary()
print(summary)
```

## Routing Patterns

### Pattern 1: Waveform Generator → Neural Network → Oscilloscope
```python
# Full ML inference pipeline with monitoring
m = MultiInstrument('192.168.1.100', platform_id=4, force_connect=True)

wg = m.set_instrument(1, WaveformGenerator)
nn = m.set_instrument(2, NeuralNetwork)
osc = m.set_instrument(3, Oscilloscope)

connections = [
    dict(source="Slot1OutA", destination="Slot2InA"),  # WaveformGen → NN Input 1
    dict(source="Slot1OutA", destination="Slot2InB"),  # WaveformGen → NN Input 2
    dict(source="Slot1OutB", destination="Slot2InC"),  # WaveformGen → NN Input 3
    dict(source="Slot1OutB", destination="Slot2InD"),  # WaveformGen → NN Input 4
    dict(source="Slot2OutA", destination="Slot3InA"),  # NN Output → Oscilloscope
]
m.set_connections(connections=connections)

# Generate test signal
wg.generate_waveform(channel=1, type='Ramp', amplitude=0.25, frequency=5e3, symmetry=100)

# Configure neural network
nn.set_input(strict=False, channel=1, low_level=-1, high_level=1)
nn.set_input_sample_rate(sample_rate=305000)
nn.upload_network("/path/to/simple_sine_model.linn")
nn.set_output(strict=False, channel=1, enabled=True, low_level=-1, high_level=1)

# Monitor output with oscilloscope
osc.set_timebase(-5e-3, 5e-3)
data = osc.get_data()
```

### Pattern 2: Custom Module → Neural Network
```python
# Preprocess signal with VHDL, then apply ML inference
mcc = m.set_instrument(1, CloudCompile, bitstream="signal_preprocessor.tar.gz")
nn = m.set_instrument(2, NeuralNetwork)

connections = [
    dict(source="Input1", destination="Slot1InA"),     # Raw signal → Custom module
    dict(source="Slot1OutA", destination="Slot2InA"),  # Preprocessed → NN
    dict(source="Slot2OutA", destination="Output1"),   # NN inference → Output
]
m.set_connections(connections=connections)

nn.set_input(channel=1, low_level=-1, high_level=1)
nn.upload_network("/path/to/classifier.linn")
nn.set_output(channel=1, enabled=True, low_level=0, high_level=1)
```

### Pattern 3: Neural Network → Custom Module
```python
# ML inference followed by custom post-processing
nn = m.set_instrument(1, NeuralNetwork)
mcc = m.set_instrument(2, CloudCompile, bitstream="decision_logic.tar.gz")

connections = [
    dict(source="Input1", destination="Slot1InA"),     # Signal → NN
    dict(source="Slot1OutA", destination="Slot2InA"),  # NN output → Custom module
    dict(source="Slot2OutA", destination="Output1"),   # Decision output
]
m.set_connections(connections=connections)
```

## Multi-Instrument Scenarios

### Signal Classification Pipeline
```python
# Real-time signal classification with ML
m = MultiInstrument('192.168.1.100', platform_id=4, force_connect=True)

nn = m.set_instrument(1, NeuralNetwork)
osc = m.set_instrument(2, Oscilloscope)

connections = [
    dict(source="Input1", destination="Slot1InA"),     # Sensor signal → NN
    dict(source="Slot1OutA", destination="Slot2InA"),  # Classification → Oscilloscope
    dict(source="Input1", destination="Slot2InB"),     # Raw signal → Oscilloscope
]
m.set_connections(connections=connections)

# Upload trained classifier
nn.upload_network("/path/to/signal_classifier.linn")
nn.set_input(channel=1, low_level=-1, high_level=1)
nn.set_output(channel=1, enabled=True, low_level=0, high_level=1)

# Monitor classification output
osc.set_timebase(-10e-3, 10e-3)
```

### Anomaly Detection
```python
# Detect anomalies in real-time data
nn = m.set_instrument(1, NeuralNetwork)
dl = m.set_instrument(2, DataLogger)

connections = [
    dict(source="Input1", destination="Slot1InA"),     # Data stream → NN
    dict(source="Slot1OutA", destination="Slot2InA"),  # Anomaly score → DataLogger
]
m.set_connections(connections=connections)

nn.upload_network("/path/to/anomaly_detector.linn")
dl.set_acquisition_mode(mode='Continuous')  # Log anomaly scores
```

## VHDL Integration

### Custom Feature Extraction → Neural Network
```python
# VHDL extracts features, NN performs classification
mcc = m.set_instrument(1, CloudCompile, bitstream="feature_extractor.tar.gz")
nn = m.set_instrument(2, NeuralNetwork)
osc = m.set_instrument(3, Oscilloscope)

connections = [
    dict(source="Input1", destination="Slot1InA"),     # Raw sensor data
    dict(source="Slot1OutA", destination="Slot2InA"),  # Feature 1 → NN
    dict(source="Slot1OutB", destination="Slot2InB"),  # Feature 2 → NN
    dict(source="Slot1OutC", destination="Slot2InC"),  # Feature 3 → NN
    dict(source="Slot1OutD", destination="Slot2InD"),  # Feature 4 → NN
    dict(source="Slot2OutA", destination="Slot3InA"),  # Classification → Oscilloscope
]
m.set_connections(connections=connections)
```

**VHDL CustomWrapper Example:**
```vhdl
-- Example: Real-time feature extraction for ML classifier
architecture FeatureExtractor of CustomWrapper is
begin
    process(Clk)
    begin
        if rising_edge(Clk) then
            -- Extract multiple features from input signal
            OutputA <= feature_1;  -- → Neural Network Input 1
            OutputB <= feature_2;  -- → Neural Network Input 2
            OutputC <= feature_3;  -- → Neural Network Input 3
            OutputD <= feature_4;  -- → Neural Network Input 4
        end if;
    end process;
end architecture;
```

### Neural Network → Control Logic
```python
# NN makes decision, VHDL executes control action
nn = m.set_instrument(1, NeuralNetwork)
mcc = m.set_instrument(2, CloudCompile, bitstream="controller.tar.gz")

connections = [
    dict(source="Input1", destination="Slot1InA"),     # Sensor → NN
    dict(source="Slot1OutA", destination="Slot2InA"),  # NN decision → Controller
    dict(source="Slot2OutA", destination="Output1"),   # Control signal
]
m.set_connections(connections=connections)
```

**VHDL CustomWrapper Example:**
```vhdl
-- Example: Control logic based on ML decision
architecture MLController of CustomWrapper is
begin
    process(Clk)
    begin
        if rising_edge(Clk) then
            -- InputA contains ML classification result
            if InputA > threshold then
                OutputA <= control_signal_high;  -- Take action
            else
                OutputA <= control_signal_low;   -- Idle
            end if;
        end if;
    end process;
end architecture;
```

## CocotB Test Comparison

**Local VHDL Test (CocotB):**
```python
# Test feature extraction locally
dut.InputA.value = sensor_signal
await RisingEdge(dut.Clk)
assert dut.OutputA.value == expected_feature_1
```

**Hardware Validation (Neural Network):**
```python
# Deploy feature extractor and validate with trained NN
nn.upload_network("/path/to/classifier.linn")
nn.set_input(channel=1, low_level=-1, high_level=1)
# Feed real sensor data, validate classification accuracy
```

## Training Neural Networks

**Note**: Neural networks must be trained **offline** using separate tools and exported to `.linn` format. The Moku instrument performs **inference only** (not training).

**Typical Workflow**:
1. Collect training data (sensor signals + labels)
2. Train network (TensorFlow, PyTorch, etc.)
3. Convert to `.linn` format (Liquid Instruments tools)
4. Upload to Moku Neural Network instrument
5. Run real-time inference

## Common Use Cases

1. **Signal Classification**: Identify signal types from sensor data
2. **Anomaly Detection**: Real-time detection of abnormal patterns
3. **Predictive Maintenance**: Predict system failures from vibration/acoustic signals
4. **Adaptive Filtering**: ML-based signal enhancement
5. **Feature-Based Control**: Use ML decisions to control physical systems

## Limitations

- **Inference Only**: Training happens offline, not on Moku
- **Platform Requirements**: Requires multi-instrument capable platforms (3+ slots)
- **Model Size**: Limited by FPGA resources (check platform specs)
- **Latency**: Real-time inference with low latency (µs-level)

## Related Instruments
- **CloudCompile**: Custom feature extraction before ML inference
- **Oscilloscope**: Monitor NN outputs
- **DataLogger**: Record inference results for analysis
- **WaveformGenerator**: Generate test signals for NN validation
